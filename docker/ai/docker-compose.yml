---
version: "3.7"
services:

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    # ports:
    #   - "8080:8080"
    networks:
      - caddy
    labels:
      caddy: searxng.madpin.dev
      caddy.reverse_proxy: "{{upstreams 8080}}"
    volumes:
      - ./searxng:/etc/searxng:rw
    restart: unless-stopped

  perplexica-backend:
    image: madpin/perplexica-backend:latest
    container_name: perplexica-backend
    depends_on:
      - searxng
    volumes:
      - ./perplexica-app-config.toml:/home/perplexica/config.toml
    # ports:
    #   - 3001:3001
    labels:
      caddy: perplexica-backend.madpin.dev
      caddy.reverse_proxy: "{{upstreams 3001}}"
    networks:
      - caddy
    restart: unless-stopped

  perplexica-app:
    image: madpin/perplexica-app:latest
    container_name: perplexica-app
    depends_on:
      - perplexica-backend
    environment:
      - NEXT_PUBLIC_API_URL=http://perplexica-backend.madpin.dev/api
      - NEXT_PUBLIC_WS_URL=ws://perplexica-backend.madpin.dev
    networks:
      - caddy
    restart: unless-stopped
    labels:
      caddy: perplexica.madpin.dev
      caddy.reverse_proxy: "{{upstreams 3000}}"
    
  chatgpt-next-web:
    image: yidadaa/chatgpt-next-web:latest
    container_name: chatgpt-next-web
    networks:
      - caddy
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Dublin
    env_file:
      - secrets.env
    labels:
      caddy: cnw.madpin.dev
      caddy.reverse_proxy: "{{upstreams 3000}}"
    restart: unless-stopped

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    networks:
      - caddy
    env_file:
      - secrets.env
      - owui.env
    volumes:
      - ./open-webui:/app/backend/data
    labels:
      caddy: owui.madpin.dev
      caddy.reverse_proxy: "{{upstreams 8080}}"
    restart: always

  # anse:
  #   image: ddiu8081/anse:latest
  #   container_name: anse
  #   networks:
  #     - caddy
  #   environment:
  #     - TZ=Europe/Dublin
  #   env_file:
  #     - secrets.env
  #   labels:
  #     caddy: anse.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 3000}}"
  #   restart: unless-stopped
  
  # chatchat:
  #   image: ghcr.io/okisdev/chatchat:latest
  #   container_name: chatchat
  #   networks:
  #     - caddy
  #   environment:
  #     - TZ=Europe/Dublin
  #   env_file:
  #     - secrets.env
  #   labels:
  #     caddy: chatchat.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 3000}}"
  #   restart: unless-stopped

  # sillytavern:
  #   build:
  #     context: https://github.com/SillyTavern/SillyTavern.git
  #     dockerfile: Dockerfile
  #   container_name: sillytavern
  #   hostname: sillytavern
  #   image: ghcr.io/sillytavern/sillytavern:latest
  #   volumes:
  #     - "./sillytavern-config:/home/node/app/config"
  #     - "./sillytavern-user:/home/node/app/public/user"
  #   labels:
  #     caddy: sillytavern.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 5100}}"
  #   network_mode: host


  # chatbotui:
  #   depends_on:
  #     - litellm
  #   image: ghcr.io/mckaywrigley/chatbot-ui:main # Deprecated
  #   # ports:
  #   #   - 3000:3000
  #   environment:
  #     - TZ=Europe/Dublin
  #   env_file:
  #     - secrets.env
  #   networks:
  #     - caddy
  #   labels:
  #     caddy: chatbotui.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 3000}}"




  litellm:
    image: ghcr.io/berriai/litellm-database:main-latest
    container_name: litellm
    restart: unless-stopped
    env_file:
      - secrets.env # Load local .env file
      - litellm.env
    volumes:
      - ./litellm_proxy_config.yaml:/app/config.yaml
      - ./google-vertex-credentials.json:/tmp/google-credentials.json
    command:
      ["--config", "/app/config.yaml", "--port", "4000", "--num_workers", "12"]
    networks:
      - caddy
    depends_on:
      ai_pg_db:
        condition: service_healthy
    labels:
      caddy: litellm.madpin.dev
      caddy.reverse_proxy: "{{upstreams 4000}}"

  # langfuse: # I'm using the online version:
  # https://cloud.langfuse.com/project/clxshkuic0004cx4whewth633/generations
  #   image: langfuse/langfuse:2
  #   container_name: langfuse
  #   restart: unless-stopped
  #   depends_on:
  #     ai_pg_db:
  #       condition: service_healthy
  #   # ports:
  #   #   - "3000:3000"
  #   environment:
  #     - DATABASE_URL=postgresql://ai_user:ai_pass@ai_pg_db:5432/langfuse
  #     - NEXTAUTH_SECRET=mysecret
  #     - SALT=mysalt
  #     - NEXTAUTH_URL=http://langfuse.madpin.dev
  #     - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-true}
  #     - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-false}
  #   networks:
  #     - caddy
  #   labels:
  #     caddy: langfuse.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 3000}}"
 
  ai_pg_db:
    image: postgres:latest
    container_name: ai_pg_db
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 3s
      timeout: 3s
      retries: 10
    shm_size: 128mb
    environment:
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=ai_pass # Load this from the secrets.env file
    networks:
      - caddy
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
      - ./init_postgres.sql:/docker-entrypoint-initdb.d/init_databases.sql

networks:
  caddy:
    external:
      name: caddy
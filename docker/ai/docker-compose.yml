---
version: "3.7"
services:
  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    # ports:
    #   - "8080:8080"
    environment:
      - BASE_URL=searxng.madpin.dev
      - INSTANCE_NAME=madpindev
    networks:
      - caddy
    labels:
      caddy: searxng.madpin.dev
      caddy.reverse_proxy: "{{upstreams 8080}}"
    volumes:
      - ./searxng:/etc/searxng:rw
    restart: unless-stopped

  # perplexica-backend:
  #   image: madpin/perplexica-backend:latest
  #   container_name: perplexica-backend
  #   depends_on:
  #     - searxng
  #   volumes:
  #     - ./perplexica-app-config.toml:/home/perplexica/config.toml
  #   # ports:
  #   #   - 3001:3001
  #   labels:
  #     caddy: perplexica-backend.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 3001}}"
  #   networks:
  #     - caddy
  #   restart: unless-stopped

  # perplexica-app:
  #   image: madpin/perplexica-app:latest
  #   container_name: perplexica-app
  #   depends_on:
  #     - perplexica-backend
  #   environment:
  #     - NEXT_PUBLIC_API_URL=http://perplexica-backend.madpin.dev/api
  #     - NEXT_PUBLIC_WS_URL=ws://perplexica-backend.madpin.dev
  #   networks:
  #     - caddy
  #   restart: unless-stopped
  #   labels:
  #     caddy: perplexica.madpin.dev
  #     caddy.reverse_proxy: "{{upstreams 3000}}"

  chatgpt-next-web:
    image: yidadaa/chatgpt-next-web:latest
    container_name: chatgpt-next-web
    # user: "${UID}:${GID}"
    networks:
      - caddy
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Dublin
    env_file:
      - secrets.env
    labels:
      caddy: cnw.madpin.dev
      caddy.reverse_proxy: "{{upstreams 3000}}"
    restart: unless-stopped
  # TODO: https://www.librechat.ai/docs/local/docker
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    networks:
      - caddy
    env_file:
      - secrets.env
      - owui.env
    volumes:
      - ./open-webui:/app/backend/data
    labels:
      caddy: owui.madpin.dev
      caddy.reverse_proxy: "{{upstreams 8081}}"
    restart: always

  sillytavern:
    build:
      context: https://github.com/SillyTavern/SillyTavern.git
      dockerfile: Dockerfile
    container_name: sillytavern
    hostname: sillytavern
    networks:
      - caddy
    image: ghcr.io/sillytavern/sillytavern:latest
    volumes:
      - "./sillytavern-config:/home/node/app/config"
      - "./sillytavern-user:/home/node/app/public/user"
      - "./sillytavern-plugins:/home/node/app/plugins"
    labels:
      caddy: sillytavern.madpin.dev
      caddy.reverse_proxy: "{{upstreams 8000}}"

  litellm:
    image: ghcr.io/berriai/litellm-database:main-latest
    container_name: litellm
    restart: unless-stopped
    env_file:
      - secrets.env # Load local .env file
      - litellm.env
    volumes:
      - ./litellm_proxy_config.yaml:/app/config.yaml
      - ./google-vertex-credentials.json:/tmp/google-credentials.json
    command:
      [
        "--config",
        "/app/config.yaml",
        "--port",
        "4000",
        "--num_workers",
        "12"
      ]
    networks:
      - caddy
    depends_on:
      ai_pg_db:
        condition: service_healthy
    labels:
      caddy: litellm.madpin.dev
      caddy.reverse_proxy: "{{upstreams 4000}}"


  ai_pg_db:
    image: postgres:latest
    container_name: ai_pg_db
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 3s
      timeout: 3s
      retries: 10
    shm_size: 128mb
    environment:
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=ai_pass # Load this from the secrets.env file
    networks:
      - caddy
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
      - ./init_postgres.sql:/docker-entrypoint-initdb.d/init_databases.sql
networks:
  caddy:
    external:
      name: caddy
